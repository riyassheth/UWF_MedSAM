{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9754143,"sourceType":"datasetVersion","datasetId":5965595},{"sourceId":9793070,"sourceType":"datasetVersion","datasetId":6001049},{"sourceId":154760,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":131494,"modelId":154298}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:35:09.721901Z","iopub.execute_input":"2024-11-03T08:35:09.722204Z","iopub.status.idle":"2024-11-03T08:37:37.200308Z","shell.execute_reply.started":"2024-11-03T08:35:09.722169Z","shell.execute_reply":"2024-11-03T08:37:37.198997Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu121\nCollecting torch==2.3.1\n  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl (781.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.18.1\n  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchaudio==2.3.1\n  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.1) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.3.1 (from torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.1) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.18.1) (10.3.0)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1)\n  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvjitlink_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (19.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.1) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.1) (1.3.0)\nInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.0\n    Uninstalling torchvision-0.19.0:\n      Successfully uninstalled torchvision-0.19.0\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.4.0\n    Uninstalling torchaudio-2.4.0:\n      Successfully uninstalled torchaudio-2.4.0\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.1.105 nvidia-nvtx-cu12-12.1.105 torch-2.3.1+cu121 torchaudio-2.3.1+cu121 torchvision-0.18.1+cu121 triton-2.3.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install hydra-core\n!pip install monai\n!pip install numba GPUtil","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:37:37.202916Z","iopub.execute_input":"2024-11-03T08:37:37.203383Z","iopub.status.idle":"2024-11-03T08:38:19.006183Z","shell.execute_reply.started":"2024-11-03T08:37:37.203329Z","shell.execute_reply":"2024-11-03T08:38:19.005202Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting hydra-core\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nCollecting omegaconf<2.4,>=2.2 (from hydra-core)\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting antlr4-python3-runtime==4.9.* (from hydra-core)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from hydra-core) (21.3)\nRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->hydra-core) (3.1.2)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=8b1c55d54e2996e342738936bd902b1e1f81c1053e61f72bc5e7b777788f2bea\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built antlr4-python3-runtime\nInstalling collected packages: antlr4-python3-runtime, omegaconf, hydra-core\nSuccessfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\nCollecting monai\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2.0,>=1.24 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\nRequirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.3.1+cu121)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->monai) (12.1.105)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\nDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: monai\nSuccessfully installed monai-1.4.0\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (0.60.0)\nCollecting GPUtil\n  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba) (0.43.0)\nRequirement already satisfied: numpy<2.1,>=1.22 in /opt/conda/lib/python3.10/site-packages (from numba) (1.26.4)\nBuilding wheels for collected packages: GPUtil\n  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=11db4a7e1c2235ca0f2fb9e128feafdbbf51ce48f8ee9afb216667e6acc342b5\n  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\nSuccessfully built GPUtil\nInstalling collected packages: GPUtil\nSuccessfully installed GPUtil-1.4.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T08:39:38.904265Z","iopub.execute_input":"2024-11-03T08:39:38.904683Z","iopub.status.idle":"2024-11-03T08:39:39.890455Z","shell.execute_reply.started":"2024-11-03T08:39:38.904644Z","shell.execute_reply":"2024-11-03T08:39:39.889164Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"!git clone -b MedSAM2 https://github.com/bowang-lab/MedSAM.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-03T08:39:44.136681Z","iopub.execute_input":"2024-11-03T08:39:44.137092Z","iopub.status.idle":"2024-11-03T08:39:47.318902Z","shell.execute_reply.started":"2024-11-03T08:39:44.137054Z","shell.execute_reply":"2024-11-03T08:39:47.317927Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Cloning into 'MedSAM'...\nremote: Enumerating objects: 948, done.\u001b[K\nremote: Counting objects: 100% (348/348), done.\u001b[K\nremote: Compressing objects: 100% (116/116), done.\u001b[K\nremote: Total 948 (delta 278), reused 232 (delta 232), pack-reused 600 (from 1)\u001b[K\nReceiving objects: 100% (948/948), 62.88 MiB | 48.49 MiB/s, done.\nResolving deltas: 100% (468/468), done.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!export CUDA_HOME=/usr/local/cuda-12.1","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:39:54.016643Z","iopub.execute_input":"2024-11-03T08:39:54.017015Z","iopub.status.idle":"2024-11-03T08:39:54.999778Z","shell.execute_reply.started":"2024-11-03T08:39:54.016980Z","shell.execute_reply":"2024-11-03T08:39:54.998638Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"cd MedSAM","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:39:55.001992Z","iopub.execute_input":"2024-11-03T08:39:55.002841Z","iopub.status.idle":"2024-11-03T08:39:55.009362Z","shell.execute_reply.started":"2024-11-03T08:39:55.002792Z","shell.execute_reply":"2024-11-03T08:39:55.008498Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/MedSAM\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt -P ./checkpoints","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:47:07.300779Z","iopub.execute_input":"2024-10-30T13:47:07.301083Z","iopub.status.idle":"2024-10-30T13:47:09.003947Z","shell.execute_reply.started":"2024-10-30T13:47:07.301051Z","shell.execute_reply":"2024-10-30T13:47:09.002802Z"},"trusted":true},"outputs":[{"name":"stdout","text":"--2024-10-30 13:47:08--  https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.51, 3.163.189.108, 3.163.189.96, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.51|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 155906050 (149M) [application/vnd.snesdev-page-table]\nSaving to: './checkpoints/sam2_hiera_tiny.pt'\n\nsam2_hiera_tiny.pt  100%[===================>] 148.68M   253MB/s    in 0.6s    \n\n2024-10-30 13:47:08 (253 MB/s) - './checkpoints/sam2_hiera_tiny.pt' saved [155906050/155906050]\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!ls /kaggle/working/MedSAM/checkpoints/sam2_hiera_tiny.pt","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:47:09.005489Z","iopub.execute_input":"2024-10-30T13:47:09.005909Z","iopub.status.idle":"2024-10-30T13:47:09.998923Z","shell.execute_reply.started":"2024-10-30T13:47:09.005862Z","shell.execute_reply":"2024-10-30T13:47:09.997632Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/MedSAM/checkpoints/sam2_hiera_tiny.pt\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install e . --no-build-isolation","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:40:00.007811Z","iopub.execute_input":"2024-11-03T08:40:00.008189Z","iopub.status.idle":"2024-11-03T08:41:26.945538Z","shell.execute_reply.started":"2024-11-03T08:40:00.008145Z","shell.execute_reply":"2024-11-03T08:41:26.944568Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Processing /kaggle/working/MedSAM\n  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting e\n  Downloading e-1.4.5.tar.gz (1.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (2.3.1+cu121)\nRequirement already satisfied: torchvision>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (0.18.1+cu121)\nRequirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (1.26.4)\nRequirement already satisfied: tqdm>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (4.66.4)\nRequirement already satisfied: hydra-core>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (1.3.2)\nCollecting iopath>=0.1.10 (from SAM-2==1.0)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pillow>=9.4.0 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (10.3.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (3.7.5)\nRequirement already satisfied: SimpleITK in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (2.4.0)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (4.10.0.84)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (0.23.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (2.2.2)\nRequirement already satisfied: monai in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (1.4.0)\nCollecting connected-components-3d (from SAM-2==1.0)\n  Downloading connected_components_3d-3.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\nRequirement already satisfied: omegaconf<2.4,>=2.2 in /opt/conda/lib/python3.10/site-packages (from hydra-core>=1.3.2->SAM-2==1.0) (2.3.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/lib/python3.10/site-packages (from hydra-core>=1.3.2->SAM-2==1.0) (4.9.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from hydra-core>=1.3.2->SAM-2==1.0) (21.3)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.10->SAM-2==1.0) (4.12.2)\nCollecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->SAM-2==1.0) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->SAM-2==1.0) (2024.1)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image->SAM-2==1.0) (1.14.1)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->SAM-2==1.0) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->SAM-2==1.0) (2024.5.22)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->SAM-2==1.0) (0.4)\nRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->SAM-2==1.0) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.3.1->SAM-2==1.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.3.1->SAM-2==1.0) (1.3.0)\nDownloading connected_components_3d-3.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nBuilding wheels for collected packages: e, SAM-2, iopath\n  Building wheel for e (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for e: filename=e-1.4.5-py3-none-any.whl size=2793 sha256=6379e1f43ff59aa09a76fc6fb177d838eac4a614976e854906e966f6d819d793\n  Stored in directory: /root/.cache/pip/wheels/3d/dc/3e/208e61209d7750644677d72934d2997177aa34e894bd398e16\n  Building wheel for SAM-2 (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for SAM-2: filename=SAM_2-1.0-cp310-cp310-linux_x86_64.whl size=440859 sha256=14f36568aad9db69e10f2e51f170355c302065bce8a0fabcc88685ddbcd44940\n  Stored in directory: /tmp/pip-ephem-wheel-cache-5r0wtlw4/wheels/74/c0/02/1809a4936a6029d67f70271cfde7a3146771b175dff0246a2d\n  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=55489c8b86caf61749ab62ff9de0f1b79a02d8ab6113936ad5da6026317e466a\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built e SAM-2 iopath\nInstalling collected packages: e, portalocker, connected-components-3d, iopath, SAM-2\nSuccessfully installed SAM-2-1.0 connected-components-3d-3.19.0 e-1.4.5 iopath-0.1.10 portalocker-2.10.1\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import hydra\nhydra.core.global_hydra.GlobalHydra.instance().clear()\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\njoin = os.path.join\nfrom tqdm import tqdm\nfrom skimage import transform\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport monai\nimport torch.nn.functional as F\nimport argparse\nimport random\nfrom datetime import datetime\nimport shutil\nimport glob\nfrom sam2.build_sam import build_sam2\nfrom typing import List, Optional, Tuple\nfrom sam2.modeling.sam2_base import SAM2Base\nfrom sam2.utils.transforms import SAM2Transforms\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:48:39.507773Z","iopub.execute_input":"2024-10-30T13:48:39.508118Z","iopub.status.idle":"2024-10-30T13:49:21.573505Z","shell.execute_reply.started":"2024-10-30T13:48:39.508080Z","shell.execute_reply":"2024-10-30T13:49:21.572508Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/kaggle/working/MedSAM/sam2/modeling/sam/transformer.py:22: UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n  OLD_GPU, USE_FLASH_ATTN, MATH_KERNEL_ON = get_sdpa_settings()\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(2024)\n\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"  # export OMP_NUM_THREADS=4\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"  # export OPENBLAS_NUM_THREADS=4\nos.environ[\"MKL_NUM_THREADS\"] = \"6\"  # export MKL_NUM_THREADS=6\nos.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"4\"  # export VECLIB_MAXIMUM_THREADS=4\nos.environ[\"NUMEXPR_NUM_THREADS\"] = \"6\"  # export NUMEXPR_NUM_THREADS=6\n\ndef show_mask(mask, ax, random_color=False):\n    if random_color:\n        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n    else:\n        color = np.array([251 / 255, 252 / 255, 30 / 255, 0.6])\n    h, w = mask.shape[-2:]\n    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n    ax.imshow(mask_image)\n\n\ndef show_box(box, ax):\n    x0, y0 = box[0], box[1]\n    w, h = box[2] - box[0], box[3] - box[1]\n    ax.add_patch(\n        plt.Rectangle((x0, y0), w, h, edgecolor=\"blue\", facecolor=(0, 0, 0, 0), lw=2)\n    )\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:49:21.577248Z","iopub.execute_input":"2024-10-30T13:49:21.578249Z","iopub.status.idle":"2024-10-30T13:49:21.592276Z","shell.execute_reply.started":"2024-10-30T13:49:21.578212Z","shell.execute_reply":"2024-10-30T13:49:21.591374Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class NpyDataset(Dataset):\n    def __init__(self, data_root, bbox_shift=20):\n        \n        self.data_root = data_root\n        self.gt_path = join(data_root, \"gts\")\n        self.img_path = join(data_root, \"images\")\n        self.gt_path_files = sorted(\n            glob.glob(join(self.gt_path, \"*.npy\"), recursive=True)\n        )\n        print(self.gt_path_files)\n        # self.gt_path_files = self.gt_path_files\n        # self.gt_path_files = [\n        #     file\n        #     for file in self.gt_path_files\n        #     if os.path.isfile(join(self.img_path, os.path.basename(file)))\n        # ]\n        self.bbox_shift = bbox_shift\n        self._transform = SAM2Transforms(resolution=1024, mask_threshold=0)\n        print(f\"number of images: {len(self.gt_path_files)}\")\n        print(self.data_root)\n        print(self.gt_path)\n        print(self.gt_path_files)\n\n\n\n    def __len__(self):\n        return len(self.gt_path_files)\n\n    def __getitem__(self, index):\n        # load npy image (1024, 1024, 3), [0,1]\n        img_name = os.path.basename(self.gt_path_files[index])\n        img = np.load(\n            join(self.img_path, img_name), \"r\", allow_pickle=True\n        )  # (1024, 1024, 3)\n        # convert the shape to (3, H, W)\n        img_1024 = self._transform(img.copy())\n        gt = np.load(\n            self.gt_path_files[index], \"r\", allow_pickle=True\n        )  # multiple labels [0, 1,4,5...], (256,256)\n        assert img_name == os.path.basename(self.gt_path_files[index]), (\n            \"img gt name error\" + self.gt_path_files[index] + self.npy_files[index]\n        )\n        assert gt.shape == (256, 256), \"ground truth should be 256x256\"\n        label_ids = np.unique(gt)[1:]\n        gt2D = np.uint8(\n            gt == random.choice(label_ids.tolist())\n        )  # only one label, (256, 256)\n        assert np.max(gt2D) == 1 and np.min(gt2D) == 0.0, \"ground truth should be 0, 1\"\n        y_indices, x_indices = np.where(gt2D > 0)\n        x_min, x_max = np.min(x_indices), np.max(x_indices)\n        y_min, y_max = np.min(y_indices), np.max(y_indices)\n        # add perturbation to bounding box coordinates\n        H, W = gt2D.shape\n        x_min = max(0, x_min - random.randint(0, self.bbox_shift))\n        x_max = min(W, x_max + random.randint(0, self.bbox_shift))\n        y_min = max(0, y_min - random.randint(0, self.bbox_shift))\n        y_max = min(H, y_max + random.randint(0, self.bbox_shift))\n\n        bboxes = np.array([x_min, y_min, x_max, y_max])*4 ## scale bbox from 256 to 1024\n\n        return (\n            img_1024, ## [3, 1024, 1024]\n            torch.tensor(gt2D[None, :, :]).long(), ## [1, 256, 256]\n            torch.tensor(bboxes).float(), \n            img_name,\n        )\n\n\n\n# # sanity test of dataset class\ntr_dataset = NpyDataset('/kaggle/input/rd-lattice-npy/kaggle/working/data/npy')\ntr_dataloader = DataLoader(tr_dataset, batch_size=4, shuffle=True)\nimages, gts, bboxes, names_temp = next(iter(tr_dataloader))\nidx = random.randint(0, images.shape[0]-1)\ninv_sam2_transform = torchvision.transforms.Compose(\n    [\n        torchvision.transforms.Normalize(mean=[0, 0, 0], std=[1 / i for i in tr_dataset._transform.std]),\n        torchvision.transforms.Normalize(mean=[-1 * i for i in tr_dataset._transform.mean], std=[1, 1, 1]),\n    ]\n)\n_, axs = plt.subplots(1, 2, figsize=(25, 25))\naxs[0].imshow(\n    inv_sam2_transform(images[idx].clone()).permute(1, 2, 0).numpy()\n)\nshow_mask(\n    cv2.resize(\n        gts[idx].squeeze(0).numpy(),\n        (1024, 1024),\n        interpolation=cv2.INTER_NEAREST\n    ),\n    axs[0]\n)\nshow_box(bboxes[idx].numpy(), axs[0])\naxs[0].axis(\"off\")\naxs[0].set_title(names_temp[idx])\nidx = random.randint(0, images.shape[0]-1)\naxs[1].imshow(\n    inv_sam2_transform(images[idx].clone()).permute(1, 2, 0).numpy()\n)\nshow_mask(\n    cv2.resize(\n        gts[idx].clone().squeeze(0).numpy(),\n        (1024, 1024),\n        interpolation=cv2.INTER_NEAREST\n    ),\n    axs[1]\n)\nshow_box(bboxes[idx].numpy(), axs[1])\naxs[1].axis(\"off\")\naxs[1].set_title(names_temp[idx])\nplt.subplots_adjust(wspace=0.01, hspace=0)\nplt.savefig(\"./data_sanitycheck.png\", bbox_inches=\"tight\", dpi=300)\nplt.close()\n\nrun_id = datetime.now().strftime(\"%Y%m%d-%H%M\")\nmodel_save_path = join('/kaggle/working/MedSAM/work_dir', 'Lattice_segmentation' + \"-\" + run_id)\ndevice = torch.device('cuda:0')\n\nclass MedSAM2(nn.Module):\n    def __init__(\n        self,\n        model,\n    ):\n        super().__init__()\n        self.sam2_model = model\n        # freeze prompt encoder\n        for param in self.sam2_model.sam_prompt_encoder.parameters():\n            param.requires_grad = False\n        \n\n    def forward(self, image, box):\n        \"\"\"\n        image: (B, 3, 1024, 1024)\n        box: (B, 2, 2)\n        \"\"\"\n        _features = self._image_encoder(image)\n        img_embed, high_res_features = _features[\"image_embed\"], _features[\"high_res_feats\"]\n        # do not compute gradients for prompt encoder\n        with torch.no_grad():\n            box_torch = torch.as_tensor(box, dtype=torch.float32, device=image.device)\n            if len(box_torch.shape) == 2:\n                box_coords = box_torch.reshape(-1, 2, 2) # (B, 4) to (B, 2, 2)\n                box_labels = torch.tensor([[2, 3]], dtype=torch.int, device=image.device)\n                box_labels = box_labels.repeat(box_torch.size(0), 1)\n            concat_points = (box_coords, box_labels)\n\n            sparse_embeddings, dense_embeddings = self.sam2_model.sam_prompt_encoder(\n                points=concat_points,\n                boxes=None,\n                masks=None,\n            )\n        low_res_masks_logits, iou_predictions, sam_tokens_out, object_score_logits = self.sam2_model.sam_mask_decoder(\n            image_embeddings=img_embed, # (B, 256, 64, 64)\n            image_pe=self.sam2_model.sam_prompt_encoder.get_dense_pe(),\n            sparse_prompt_embeddings=sparse_embeddings,\n            dense_prompt_embeddings=dense_embeddings,\n            multimask_output=False,\n            repeat_image=False,\n            high_res_features=high_res_features,\n        )\n\n        return low_res_masks_logits\n    \n    def _image_encoder(self, input_image):\n        backbone_out = self.sam2_model.forward_image(input_image)\n        _, vision_feats, _, _ = self.sam2_model._prepare_backbone_features(backbone_out)\n        # Add no_mem_embed, which is added to the lowest rest feat. map during training on videos\n        if self.sam2_model.directly_add_no_mem_embed:\n            vision_feats[-1] = vision_feats[-1] + self.sam2_model.no_mem_embed\n        bb_feat_sizes = [(256, 256), (128, 128), (64, 64)]\n        feats = [\n            feat.permute(1, 2, 0).view(input_image.size(0), -1, *feat_size)\n            for feat, feat_size in zip(vision_feats[::-1], bb_feat_sizes[::-1])\n        ][::-1]\n        _features = {\"image_embed\": feats[-1], \"high_res_feats\": feats[:-1]}\n\n        return _features\n\n\n# %%\n","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:49:21.593607Z","iopub.execute_input":"2024-10-30T13:49:21.593909Z","iopub.status.idle":"2024-10-30T13:49:34.627093Z","shell.execute_reply.started":"2024-10-30T13:49:21.593877Z","shell.execute_reply":"2024-10-30T13:49:34.626297Z"},"trusted":true},"outputs":[{"name":"stdout","text":"['/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/AMYN.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_04 AM-70_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_13 AM-100_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_14 AM-110_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_15 AM-120_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_46 AM-300_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_54 AM-350_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_58 AM-390_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_00 AM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_00 AM-420.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_01 AM-430.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_02 AM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_02 AM-450.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_05 AM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_06 AM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_12 AM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_20 AM-70.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_21 AM-80.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_26 AM-110.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_27 AM-120.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_30_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_32 AM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_32_31-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_36_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_39_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_40_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_41_56-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_46_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_53_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_59_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_00_37-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_03_35-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_04_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_05_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_06_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_07_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_09_12-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_11 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_12 PM-870.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_14_10-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_24_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_27_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_31_49-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_59_39-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_03_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_05_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_14_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_20_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_20_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_21_29-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_34_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_40_16-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_40_58-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_42_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_48_10-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_49_57-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_51_28-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_54_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_54_27-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_56_51-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_59_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_00_51-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_01_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_01_55-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_02_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_03_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_03_31-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_05_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_05_41-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_25_00-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_25_38-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_26_22-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_27_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_30_55-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_32_19-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_32_48-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_34_17-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_34_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_37_00-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_38_13-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_38_57-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_40_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_42_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_44_41-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_45_22-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_46_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_47_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_47_54-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_48_29-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_50_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_50_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_54_25-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_55_50-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_30_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_31_30-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_32_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_32_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_33_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_34_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_35_05-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_35_26-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_37_03-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_42_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_44_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_47_03-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_48_23-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_49_19-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_49_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_50_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-17_12_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_37 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_38 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_43 PM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_44 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_09 PM-2680.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_09 PM-2700.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_12 PM-60.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-3_46 PM-4620.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_26 PM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_27 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_39 PM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_40 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_42 PM-70.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_42 PM-80.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_43 PM-90.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_45 PM-100.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_47 PM-100.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_55 PM-130.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_56 PM-170.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_56 PM-5870.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_57 PM-180.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_58 PM-190.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_58 PM-200.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-210.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-220.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-5990.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_00 PM-230.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_04 PM-6120.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_09 PM-280.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_10 PM-290.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_13 PM-310.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_13 PM-330.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_18 PM-6400.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_18 PM-6420.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_21 PM-340.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_22 PM-350.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_23 PM-360.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_23 PM-380.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_31 PM-6720.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_39 PM-6860.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_54 PM-7270.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_59 PM-280.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_16 PM-450.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_18 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_19 PM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_23 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_27 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_35 PM-60.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_37 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_39 PM-560.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_41 PM-8580.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_46 PM-8800.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_47 PM-640.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_47 PM-660.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_58 PM-9050.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_21 PM-9840.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_30 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_39 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_43 PM-510.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_55 PM-700.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-8_06 PM-1060.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/DALAL.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/FRANCO_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/HUMA TASLEEM.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/MUBASSHIRA.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/NITASHA_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/RIZWAN KHAN.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHAHID_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHILPA.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHROFF.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHWETA_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/WhatsApp Image 2024-08-10 at 22.npy']\nnumber of images: 182\n/kaggle/input/rd-lattice-npy/kaggle/working/data/npy\n/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts\n['/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/AMYN.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_04 AM-70_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_13 AM-100_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_14 AM-110_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_15 AM-120_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_46 AM-300_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_54 AM-350_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_58 AM-390_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_00 AM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_00 AM-420.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_01 AM-430.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_02 AM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_02 AM-450.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_05 AM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_06 AM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_12 AM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_20 AM-70.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_21 AM-80.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_26 AM-110.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_27 AM-120.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_30_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_32 AM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_32_31-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_36_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_39_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_40_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_41_56-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_46_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_53_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_59_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_00_37-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_03_35-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_04_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_05_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_06_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_07_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_09_12-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_11 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_12 PM-870.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_14_10-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_24_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_27_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_31_49-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_59_39-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_03_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_05_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_14_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_20_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_20_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_21_29-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_34_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_40_16-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_40_58-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_42_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_48_10-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_49_57-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_51_28-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_54_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_54_27-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_56_51-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_59_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_00_51-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_01_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_01_55-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_02_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_03_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_03_31-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_05_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_05_41-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_25_00-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_25_38-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_26_22-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_27_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_30_55-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_32_19-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_32_48-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_34_17-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_34_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_37_00-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_38_13-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_38_57-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_40_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_42_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_44_41-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_45_22-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_46_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_47_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_47_54-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_48_29-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_50_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_50_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_54_25-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_55_50-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_30_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_31_30-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_32_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_32_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_33_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_34_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_35_05-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_35_26-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_37_03-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_42_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_44_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_47_03-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_48_23-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_49_19-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_49_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_50_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-17_12_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_37 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_38 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_43 PM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_44 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_09 PM-2680.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_09 PM-2700.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_12 PM-60.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-3_46 PM-4620.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_26 PM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_27 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_39 PM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_40 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_42 PM-70.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_42 PM-80.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_43 PM-90.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_45 PM-100.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_47 PM-100.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_55 PM-130.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_56 PM-170.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_56 PM-5870.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_57 PM-180.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_58 PM-190.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_58 PM-200.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-210.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-220.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-5990.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_00 PM-230.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_04 PM-6120.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_09 PM-280.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_10 PM-290.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_13 PM-310.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_13 PM-330.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_18 PM-6400.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_18 PM-6420.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_21 PM-340.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_22 PM-350.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_23 PM-360.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_23 PM-380.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_31 PM-6720.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_39 PM-6860.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_54 PM-7270.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_59 PM-280.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_16 PM-450.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_18 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_19 PM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_23 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_27 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_35 PM-60.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_37 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_39 PM-560.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_41 PM-8580.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_46 PM-8800.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_47 PM-640.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_47 PM-660.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_58 PM-9050.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_21 PM-9840.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_30 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_39 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_43 PM-510.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_55 PM-700.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-8_06 PM-1060.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/DALAL.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/FRANCO_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/HUMA TASLEEM.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/MUBASSHIRA.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/NITASHA_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/RIZWAN KHAN.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHAHID_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHILPA.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHROFF.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHWETA_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/WhatsApp Image 2024-08-10 at 22.npy']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def main():\n    torch.cuda.empty_cache()\n    os.makedirs(model_save_path, exist_ok=True)\n    # shutil.copyfile(\n    #     ,join(model_save_path, run_id + \"_\" + os.path.basename(__file__))\n    # )\n\n    model_cfg = 'sam2_hiera_t.yaml'\n    sam2_checkpoint = '/kaggle/working/MedSAM/checkpoints/sam2_hiera_tiny.pt'\n    sam2_model = build_sam2(model_cfg, sam2_checkpoint, device= device, apply_postprocessing=True)\n    medsam_model = MedSAM2(model=sam2_model)\n    medsam_model.train()\n\n    print(\n        \"Number of total parameters: \",\n        sum(p.numel() for p in medsam_model.parameters()),\n    ) \n    print(\n        \"Number of trainable parameters: \",\n        sum(p.numel() for p in medsam_model.parameters() if p.requires_grad),\n    )  \n\n    img_mask_encdec_params = list(medsam_model.sam2_model.image_encoder.parameters()) + list(\n        medsam_model.sam2_model.sam_mask_decoder.parameters()\n    )\n    optimizer = torch.optim.AdamW(\n        img_mask_encdec_params, lr=6e-5, weight_decay=0.01\n    )\n    print(\n        \"Number of image encoder and mask decoder parameters: \",\n        sum(p.numel() for p in img_mask_encdec_params if p.requires_grad),\n    )  \n    seg_loss = monai.losses.DiceLoss(sigmoid=True, squared_pred=True, reduction=\"mean\")\n    # cross entropy loss\n    ce_loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n\n    num_epochs = 50\n    losses = []\n    best_loss = 1e10\n    train_dataset = NpyDataset('/kaggle/input/rd-lattice-npy/kaggle/working/data/npy')\n\n    print(\"Number of training samples: \", len(train_dataset))\n    train_dataloader = DataLoader(\n        train_dataset,\n        batch_size= 4,\n        shuffle=False,\n        num_workers=0,\n        pin_memory=True,\n    )\n\n    start_epoch = 0\n    resume = None\n    if resume is not None:\n        if os.path.isfile(resume):\n            ## Map model to be loaded to specified single GPU\n            print(\"=> loading checkpoint '{}'\".format(resume))\n            checkpoint = torch.load(resume, map_location=device)\n            start_epoch = checkpoint[\"epoch\"] + 1\n            medsam_model.load_state_dict(checkpoint[\"model\"], strict=True)\n            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    for epoch in range(start_epoch, num_epochs):\n        epoch_loss = 0\n        for step, (image, gt2D, boxes, _) in enumerate(tqdm(train_dataloader)):\n            optimizer.zero_grad()\n            boxes_np = boxes.detach().cpu().numpy()\n            image, gt2D = image.to(device), gt2D.to(device)\n            \n            medsam_pred = medsam_model(image, boxes_np)\n            loss = seg_loss(medsam_pred, gt2D) + ce_loss(medsam_pred, gt2D.float())                \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            epoch_loss += loss.item()\n\n        epoch_loss /= step\n        losses.append(epoch_loss)\n        print(\n            f'Time: {datetime.now().strftime(\"%Y%m%d-%H%M\")}, Epoch: {epoch}, Loss: {epoch_loss}'\n        )\n        ## save the latest model\n        checkpoint = {\n            \"model\": medsam_model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n            \"epoch\": epoch,\n        }\n        torch.save(checkpoint, join(model_save_path, \"medsam_model_latest.pth\"))\n        ## save the best model\n        if epoch_loss < best_loss:\n            best_loss = epoch_loss\n            checkpoint = {\n                \"model\": medsam_model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"epoch\": epoch,\n            }\n            torch.save(checkpoint, join(model_save_path, \"medsam_model_best.pth\"))\n\n        # %% plot loss\n        plt.plot(losses)\n        plt.title(\"Dice + Cross Entropy Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.savefig(join(model_save_path, 'Lattice_segmentation' + \"train_loss.png\"))\n        plt.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:49:34.628475Z","iopub.execute_input":"2024-10-30T13:49:34.629140Z","iopub.status.idle":"2024-10-30T13:49:34.649156Z","shell.execute_reply.started":"2024-10-30T13:49:34.629082Z","shell.execute_reply":"2024-10-30T13:49:34.648260Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# from numba import cuda\n# from GPUtil import showUtilization as GPU_usage\n# GPU_usage()\n# cuda.select_device(0)\n# cuda.close()\n# cuda.select_device(0)\n# GPU_usage()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:49:34.650342Z","iopub.execute_input":"2024-10-30T13:49:34.650661Z","iopub.status.idle":"2024-10-30T13:49:34.667821Z","shell.execute_reply.started":"2024-10-30T13:49:34.650628Z","shell.execute_reply":"2024-10-30T13:49:34.666947Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"main()","metadata":{"execution":{"iopub.status.busy":"2024-10-30T13:49:34.668972Z","iopub.execute_input":"2024-10-30T13:49:34.670695Z","iopub.status.idle":"2024-10-30T14:47:57.572315Z","shell.execute_reply.started":"2024-10-30T13:49:34.670659Z","shell.execute_reply":"2024-10-30T14:47:57.571066Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Number of total parameters:  38945986\nNumber of trainable parameters:  38939766\nNumber of image encoder and mask decoder parameters:  31434245\n['/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/AMYN.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_04 AM-70_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_13 AM-100_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_14 AM-110_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_15 AM-120_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_46 AM-300_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_54 AM-350_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_58 AM-390_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_00 AM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_00 AM-420.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_01 AM-430.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_02 AM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_02 AM-450.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_05 AM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_06 AM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_12 AM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_20 AM-70.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_21 AM-80.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_26 AM-110.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_27 AM-120.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_30_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_32 AM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_32_31-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_36_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_39_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_40_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_41_56-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_46_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_53_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_59_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_00_37-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_03_35-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_04_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_05_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_06_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_07_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_09_12-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_11 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_12 PM-870.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_14_10-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_24_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_27_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_31_49-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_59_39-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_03_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_05_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_14_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_20_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_20_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_21_29-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_34_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_40_16-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_40_58-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_42_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_48_10-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_49_57-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_51_28-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_54_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_54_27-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_56_51-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_59_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_00_51-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_01_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_01_55-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_02_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_03_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_03_31-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_05_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_05_41-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_25_00-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_25_38-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_26_22-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_27_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_30_55-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_32_19-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_32_48-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_34_17-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_34_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_37_00-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_38_13-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_38_57-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_40_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_42_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_44_41-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_45_22-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_46_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_47_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_47_54-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_48_29-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_50_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_50_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_54_25-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_55_50-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_30_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_31_30-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_32_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_32_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_33_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_34_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_35_05-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_35_26-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_37_03-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_42_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_44_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_47_03-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_48_23-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_49_19-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_49_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_50_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-17_12_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_37 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_38 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_43 PM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_44 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_09 PM-2680.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_09 PM-2700.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_12 PM-60.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-3_46 PM-4620.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_26 PM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_27 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_39 PM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_40 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_42 PM-70.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_42 PM-80.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_43 PM-90.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_45 PM-100.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_47 PM-100.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_55 PM-130.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_56 PM-170.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_56 PM-5870.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_57 PM-180.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_58 PM-190.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_58 PM-200.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-210.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-220.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-5990.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_00 PM-230.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_04 PM-6120.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_09 PM-280.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_10 PM-290.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_13 PM-310.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_13 PM-330.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_18 PM-6400.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_18 PM-6420.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_21 PM-340.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_22 PM-350.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_23 PM-360.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_23 PM-380.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_31 PM-6720.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_39 PM-6860.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_54 PM-7270.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_59 PM-280.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_16 PM-450.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_18 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_19 PM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_23 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_27 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_35 PM-60.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_37 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_39 PM-560.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_41 PM-8580.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_46 PM-8800.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_47 PM-640.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_47 PM-660.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_58 PM-9050.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_21 PM-9840.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_30 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_39 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_43 PM-510.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_55 PM-700.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-8_06 PM-1060.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/DALAL.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/FRANCO_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/HUMA TASLEEM.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/MUBASSHIRA.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/NITASHA_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/RIZWAN KHAN.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHAHID_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHILPA.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHROFF.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHWETA_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/WhatsApp Image 2024-08-10 at 22.npy']\nnumber of images: 182\n/kaggle/input/rd-lattice-npy/kaggle/working/data/npy\n/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts\n['/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/AMYN.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_04 AM-70_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_13 AM-100_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_14 AM-110_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_15 AM-120_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_46 AM-300_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_54 AM-350_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-10_58 AM-390_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_00 AM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_00 AM-420.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_01 AM-430.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_02 AM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_02 AM-450.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_05 AM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_06 AM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_12 AM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_20 AM-70.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_21 AM-80.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_26 AM-110.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_27 AM-120.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_30_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_32 AM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_32_31-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_36_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_39_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_40_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_41_56-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_46_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_53_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-11_59_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_00_37-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_03_35-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_04_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_05_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_06_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_07_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_09_12-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_11 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_12 PM-870.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_14_10-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_24_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_27_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_31_49-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-12_59_39-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_03_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_05_47-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_14_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_20_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_20_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_21_29-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_34_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_40_16-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_40_58-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_42_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_48_10-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_49_57-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_51_28-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_54_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_54_27-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_56_51-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-13_59_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_00_51-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_01_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_01_55-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_02_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_03_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_03_31-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_05_01-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_05_41-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_25_00-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_25_38-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_26_22-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_27_44-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_30_55-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_32_19-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_32_48-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_34_17-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_34_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_37_00-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_38_13-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_38_57-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_40_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_42_20-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_44_41-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_45_22-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_46_40-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_47_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_47_54-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_48_29-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_50_18-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_50_32-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_54_25-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-14_55_50-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_30_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_31_30-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_32_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_32_43-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_33_08-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_34_24-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_35_05-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_35_26-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_37_03-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_42_06-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_44_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_47_03-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_48_23-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_49_19-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_49_36-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-15_50_02-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-17_12_42-2.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_37 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_38 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_43 PM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-1_44 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_09 PM-2680.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_09 PM-2700.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-2_12 PM-60.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-3_46 PM-4620.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_26 PM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_27 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_39 PM-40.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_40 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_42 PM-70.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_42 PM-80.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_43 PM-90.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_45 PM-100.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_47 PM-100.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_55 PM-130.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_56 PM-170.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_56 PM-5870.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_57 PM-180.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_58 PM-190.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_58 PM-200.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-210.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-220.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-4_59 PM-5990.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_00 PM-230.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_04 PM-6120.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_09 PM-280.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_10 PM-290.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_13 PM-310.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_13 PM-330.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_18 PM-6400.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_18 PM-6420.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_21 PM-340.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_22 PM-350.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_23 PM-360.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_23 PM-380.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_31 PM-6720.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_39 PM-6860.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_54 PM-7270.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-5_59 PM-280.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_16 PM-450.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_18 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_19 PM-20.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_23 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_27 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_35 PM-60.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_37 PM-10.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_39 PM-560.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_41 PM-8580.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_46 PM-8800.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_47 PM-640.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_47 PM-660.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-6_58 PM-9050.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_21 PM-9840.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_30 PM-30.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_39 PM-50.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_43 PM-510.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-7_55 PM-700.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/Capture-8_06 PM-1060.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/DALAL.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/FRANCO_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/HUMA TASLEEM.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/MUBASSHIRA.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/NITASHA_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/RIZWAN KHAN.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHAHID_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHILPA.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHROFF.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/SHWETA_1.npy', '/kaggle/input/rd-lattice-npy/kaggle/working/data/npy/gts/WhatsApp Image 2024-08-10 at 22.npy']\nNumber of training samples:  182\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:37<00:00,  2.12s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1351, Epoch: 0, Loss: 0.4151420904530419\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1352, Epoch: 1, Loss: 0.32202064196268715\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1353, Epoch: 2, Loss: 0.2909133689271079\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1354, Epoch: 3, Loss: 0.3012466483645969\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1355, Epoch: 4, Loss: 0.3042205191320843\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1357, Epoch: 5, Loss: 0.2818256325191922\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1358, Epoch: 6, Loss: 0.2367341751853625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:06<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1359, Epoch: 7, Loss: 0.22148749000496334\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:06<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1400, Epoch: 8, Loss: 0.1949214317732387\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:06<00:00,  1.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1401, Epoch: 9, Loss: 0.18227608336342704\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:06<00:00,  1.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1402, Epoch: 10, Loss: 0.1870309144258499\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:06<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1403, Epoch: 11, Loss: 0.18081925908724467\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1405, Epoch: 12, Loss: 0.156743586063385\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1406, Epoch: 13, Loss: 0.18847553117407692\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1407, Epoch: 14, Loss: 0.18600763893789715\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1408, Epoch: 15, Loss: 0.16038041197591357\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1409, Epoch: 16, Loss: 0.14769685003492566\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1410, Epoch: 17, Loss: 0.1352394562628534\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1411, Epoch: 18, Loss: 0.1325434903303782\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.46s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1413, Epoch: 19, Loss: 0.12256890154547162\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1414, Epoch: 20, Loss: 0.11940642727745904\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1415, Epoch: 21, Loss: 0.10925304326746199\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1416, Epoch: 22, Loss: 0.1349564681450526\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1417, Epoch: 23, Loss: 0.11449364539649752\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1418, Epoch: 24, Loss: 0.11253810632559988\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1420, Epoch: 25, Loss: 0.11021505660480924\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1421, Epoch: 26, Loss: 0.10709871732526355\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1422, Epoch: 27, Loss: 0.09624455372492473\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1423, Epoch: 28, Loss: 0.09801560458209779\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1424, Epoch: 29, Loss: 0.09580262518591351\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1425, Epoch: 30, Loss: 0.09635219979617331\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1427, Epoch: 31, Loss: 0.10516531798574659\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:09<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1428, Epoch: 32, Loss: 0.09827977435456382\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1429, Epoch: 33, Loss: 0.07934461302227444\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1430, Epoch: 34, Loss: 0.08547538104984495\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1431, Epoch: 35, Loss: 0.08276784809099304\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.49s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1432, Epoch: 36, Loss: 0.07665406250291401\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1433, Epoch: 37, Loss: 0.07043782364990976\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1435, Epoch: 38, Loss: 0.07263031229376793\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1436, Epoch: 39, Loss: 0.06447592112753127\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1437, Epoch: 40, Loss: 0.07637272857957417\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1438, Epoch: 41, Loss: 0.0739037696686056\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1439, Epoch: 42, Loss: 0.07781817159718937\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1440, Epoch: 43, Loss: 0.06598774964610736\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1442, Epoch: 44, Loss: 0.061830719312032066\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.47s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1443, Epoch: 45, Loss: 0.060174447298049924\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1444, Epoch: 46, Loss: 0.06549888940321075\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.50s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1445, Epoch: 47, Loss: 0.06949320642484559\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:07<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1446, Epoch: 48, Loss: 0.056202803800503416\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 46/46 [01:08<00:00,  1.48s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241030-1447, Epoch: 49, Loss: 0.05419553000893858\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#Evaluate Model on validatiion dataset\nimport numpy as np\nfrom os.path import join\nfrom os import makedirs, listdir\nfrom tqdm import tqdm\nfrom matplotlib import pyplot as plt\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport SimpleITK as sitk\nimport cv2\nfrom skimage import measure\nfrom tqdm import tqdm\nimport argparse\n\nfrom sam2.build_sam import build_sam2\nfrom sam2.utils.transforms import SAM2Transforms\n\nfrom torch import multiprocessing as mp","metadata":{"execution":{"iopub.status.busy":"2024-11-03T08:59:32.731020Z","iopub.execute_input":"2024-11-03T08:59:32.731838Z","iopub.status.idle":"2024-11-03T08:59:32.738087Z","shell.execute_reply.started":"2024-11-03T08:59:32.731799Z","shell.execute_reply":"2024-11-03T08:59:32.737028Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#%% set seeds\ntorch.set_float32_matmul_precision('high')\ntorch.manual_seed(2024)\ntorch.cuda.manual_seed(2024)\nnp.random.seed(2024)\n\nlabel_dict = {\n    1: 'Lattice_LR',\n    2: 'Lattic_HR',\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-03T08:59:35.732568Z","iopub.execute_input":"2024-11-03T08:59:35.733194Z","iopub.status.idle":"2024-11-03T08:59:35.739681Z","shell.execute_reply.started":"2024-11-03T08:59:35.733157Z","shell.execute_reply":"2024-11-03T08:59:35.738940Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class MedSAM2(nn.Module):\n    def __init__(\n        self,\n        model,\n    ):\n        super().__init__()\n        self.sam2_model = model\n        # freeze prompt encoder\n        for param in self.sam2_model.sam_prompt_encoder.parameters():\n            param.requires_grad = False\n        \n\n    def forward(self, image, box):\n        \"\"\"\n        image: (B, 3, 1024, 1024)\n        box: (B, 2, 2)\n        \"\"\"\n        _features = self._image_encoder(image)\n        img_embed, high_res_features = _features[\"image_embed\"], _features[\"high_res_feats\"]\n        # do not compute gradients for prompt encoder\n        with torch.no_grad():\n            box_torch = torch.as_tensor(box, dtype=torch.float32, device=image.device)\n            if len(box_torch.shape) == 2:\n                box_coords = box_torch.reshape(-1, 2, 2) # (B, 4) to (B, 2, 2)\n                box_labels = torch.tensor([[2, 3]], dtype=torch.int, device=image.device)\n                box_labels = box_labels.repeat(box_torch.size(0), 1)\n            concat_points = (box_coords, box_labels)\n\n            sparse_embeddings, dense_embeddings = self.sam2_model.sam_prompt_encoder(\n                points=concat_points,\n                boxes=None,\n                masks=None,\n            )\n        low_res_masks_logits, iou_predictions, sam_tokens_out, object_score_logits = self.sam2_model.sam_mask_decoder(\n            image_embeddings=img_embed, # (1, 256, 64, 64)\n            image_pe=self.sam2_model.sam_prompt_encoder.get_dense_pe(),\n            sparse_prompt_embeddings=sparse_embeddings,\n            dense_prompt_embeddings=dense_embeddings,\n            multimask_output=False,\n            repeat_image=False,\n            high_res_features=high_res_features,\n        )\n\n        return low_res_masks_logits\n\n\n    def _image_encoder(self, input_image):\n        backbone_out = self.sam2_model.forward_image(input_image)\n        _, vision_feats, _, _ = self.sam2_model._prepare_backbone_features(backbone_out)\n        if self.sam2_model.directly_add_no_mem_embed:\n            vision_feats[-1] = vision_feats[-1] + self.sam2_model.no_mem_embed\n        bb_feat_sizes = [(256, 256), (128, 128), (64, 64)]\n        feats = [\n            feat.permute(1, 2, 0).view(input_image.size(0), -1, *feat_size)\n            for feat, feat_size in zip(vision_feats[::-1], bb_feat_sizes[::-1])\n        ][::-1]\n\n        _features = {\"image_embed\": feats[-1], \"high_res_feats\": feats[:-1]}\n\n        return _features\n\n\ndef getLargestCC(segmentation):\n    labels = measure.label(segmentation)\n    largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1\n    return largestCC.astype(np.uint8)\n\nimage_size = 1024\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# visualization functions\n# source: https://github.com/facebookresearch/segment-anything/blob/main/notebooks/predictor_example.ipynb\n# change color to avoid red and green\ndef show_mask(mask, ax, random_color=False):\n    if random_color:\n        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n    else:\n        color = np.array([251/255, 252/255, 30/255, 0.6])\n    h, w = mask.shape[-2:]\n    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n    ax.imshow(mask_image)\n    \ndef show_box(box, ax):\n    x0, y0 = box[0], box[1]\n    w, h = box[2] - box[0], box[3] - box[1]\n    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='blue', facecolor=(0,0,0,0), lw=2))\n\ndef get_bbox(mask, bbox_shift=5):\n    y_indices, x_indices = np.where(mask > 0)\n    x_min, x_max = np.min(x_indices), np.max(x_indices)\n    y_min, y_max = np.min(y_indices), np.max(y_indices)\n    # add perturbation to bounding box coordinates\n    H, W = mask.shape\n    x_min = max(0, x_min - bbox_shift)\n    x_max = min(W, x_max + bbox_shift)\n    y_min = max(0, y_min - bbox_shift)\n    y_max = min(H, y_max + bbox_shift)\n    bboxes = np.array([x_min, y_min, x_max, y_max])\n    return bboxes\n\n@torch.no_grad()\ndef medsam_inference(\n    medsam_model,\n    features,\n    box_1024,\n    H, W\n    ):\n    img_embed, high_res_features = features[\"image_embed\"], features[\"high_res_feats\"]\n    box_torch = torch.as_tensor(box_1024, dtype=torch.float32, device=img_embed.device)\n    print(box_torch.shape)\n    if len(box_torch.shape) == 2:\n        box_coords = box_torch.reshape(-1, 2, 2) # (B, 4) to (B, 2, 2)\n        box_labels = torch.tensor([[2, 3]], dtype=torch.int, device=img_embed.device)\n        box_labels = box_labels.repeat(box_torch.size(0), 1)\n    concat_points = (box_coords, box_labels)\n\n    sparse_embeddings, dense_embeddings = medsam_model.sam2_model.sam_prompt_encoder(\n        points=concat_points,\n        boxes=None,\n        masks=None,\n    )\n    low_res_masks_logits, iou_predictions, sam_tokens_out, object_score_logits = medsam_model.sam2_model.sam_mask_decoder(\n        image_embeddings=img_embed, # (1, 256, 64, 64)\n        image_pe=medsam_model.sam2_model.sam_prompt_encoder.get_dense_pe(),\n        sparse_prompt_embeddings=sparse_embeddings,\n        dense_prompt_embeddings=dense_embeddings,\n        multimask_output=False,\n        repeat_image=False,\n        high_res_features=high_res_features,\n    )\n\n    low_res_pred = torch.sigmoid(low_res_masks_logits)  # (1, 1, 256, 256)\n\n    low_res_pred = F.interpolate(\n        low_res_pred,\n        size=(H, W),\n        mode=\"bilinear\",\n        align_corners=False,\n    )  # (1, 1, gt.shape)\n    low_res_pred = low_res_pred.squeeze().cpu().numpy()  # (256, 256)\n    medsam_seg = (low_res_pred > 0.5).astype(np.uint8)\n\n    return medsam_seg\n\nvisualize = True\ndata_root = '/kaggle/input/lattice-npy-full/lattice_npy_full/images'\npred_save_dir = 'segs/sam2'\nmakedirs(pred_save_dir, exist_ok=True)\nbbox_shift = 20\n\ndevice = 'cuda:0'\nmodel_cfg = 'sam2_hiera_t.yaml'\nsam2_checkpoint = None\nmedsam2_checkpoint = '/kaggle/input/lattice_medsam_best/pytorch/default/1/lattice_medsam_model_best.pth'\nnum_workers = 4\n\nsam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device, mode=\"eval\", apply_postprocessing=True)\nmedsam2_checkpoint = torch.load(medsam2_checkpoint, map_location=\"cpu\")\nmedsam_model = MedSAM2(model=sam2_model)\nmedsam_model.load_state_dict(medsam2_checkpoint[\"model\"], strict=True)\nmedsam_model.eval()\nsam2_transforms = SAM2Transforms(resolution=1024, mask_threshold=0)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T09:50:14.806305Z","iopub.execute_input":"2024-11-03T09:50:14.806688Z","iopub.status.idle":"2024-11-03T09:50:15.733443Z","shell.execute_reply.started":"2024-11-03T09:50:14.806642Z","shell.execute_reply":"2024-11-03T09:50:15.732406Z"},"trusted":true},"outputs":[],"execution_count":37},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-10-30T14:47:59.279835Z","iopub.execute_input":"2024-10-30T14:47:59.280217Z","iopub.status.idle":"2024-10-30T14:47:59.859755Z","shell.execute_reply.started":"2024-10-30T14:47:59.280175Z","shell.execute_reply":"2024-10-30T14:47:59.858681Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"mp.set_start_method('spawn')\nwith mp.Pool(processes=num_workers) as pool:\n    list(tqdm(pool.imap_unordered(main, names), total=len(names)))","metadata":{"execution":{"iopub.status.busy":"2024-10-30T14:47:59.861077Z","iopub.execute_input":"2024-10-30T14:47:59.861484Z","iopub.status.idle":"2024-10-30T14:47:59.999029Z","shell.execute_reply.started":"2024-10-30T14:47:59.861437Z","shell.execute_reply":"2024-10-30T14:47:59.998147Z"},"trusted":true},"outputs":[],"execution_count":19}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9768951,"sourceType":"datasetVersion","datasetId":5965656}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n# !pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121 \n# !git clone -b MedSAM2 https://github.com/bowang-lab/MedSAM.git\n# !export CUDA_HOME=/usr/local/cuda-12.1\nos.chdir('/kaggle/working/MedSAM/')\n!pip install --no-build-isolation -e .\n!wget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt -P ./checkpoints\n\nimport shutil\nshutil.copytree('/kaggle/input/ddr-segmentation-dataset/kaggle/working/data','/kaggle/working/data')\nos.remove('/kaggle/working/data/train/gts/007-2402-100.npy')\nos.remove('/kaggle/working/data/train/images/007-2402-100.npy')\nos.remove('/kaggle/working/data/train/gts/007-2366-100.npy')\nos.remove('/kaggle/working/data/train/images/007-2366-100.npy')\nos.remove('/kaggle/working/data/valid/gts/007-2983-100.npy')\nos.remove('/kaggle/working/data/valid/images/007-2983-100.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:53:28.527461Z","iopub.execute_input":"2024-11-01T18:53:28.528164Z","iopub.status.idle":"2024-11-01T18:55:10.242221Z","shell.execute_reply.started":"2024-11-01T18:53:28.528121Z","shell.execute_reply":"2024-11-01T18:55:10.240786Z"}},"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/MedSAM\n  Checking if build backend supports build_editable ... \u001b[?25ldone\n\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (2.3.1+cu121)\nRequirement already satisfied: torchvision>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (0.18.1+cu121)\nRequirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (1.26.4)\nRequirement already satisfied: tqdm>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (4.66.4)\nCollecting hydra-core>=1.3.2 (from SAM-2==1.0)\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nCollecting iopath>=0.1.10 (from SAM-2==1.0)\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pillow>=9.4.0 in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (10.3.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (3.7.5)\nRequirement already satisfied: SimpleITK in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (2.4.0)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (4.10.0.84)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (0.23.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from SAM-2==1.0) (2.2.2)\nCollecting monai (from SAM-2==1.0)\n  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\nCollecting connected-components-3d (from SAM-2==1.0)\n  Downloading connected_components_3d-3.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\nCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->SAM-2==1.0)\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->SAM-2==1.0)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from hydra-core>=1.3.2->SAM-2==1.0) (21.3)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from iopath>=0.1.10->SAM-2==1.0) (4.12.2)\nCollecting portalocker (from iopath>=0.1.10->SAM-2==1.0)\n  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.3.1->SAM-2==1.0) (2.3.1)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.1->SAM-2==1.0) (12.1.105)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->SAM-2==1.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->SAM-2==1.0) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->SAM-2==1.0) (2024.1)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image->SAM-2==1.0) (1.14.1)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->SAM-2==1.0) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->SAM-2==1.0) (2024.5.22)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->SAM-2==1.0) (0.4)\nRequirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.4,>=2.2->hydra-core>=1.3.2->SAM-2==1.0) (6.0.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->SAM-2==1.0) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.3.1->SAM-2==1.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=2.3.1->SAM-2==1.0) (1.3.0)\nDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading connected_components_3d-3.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\nBuilding wheels for collected packages: SAM-2, antlr4-python3-runtime, iopath\n  Building editable for SAM-2 (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for SAM-2: filename=SAM_2-1.0-0.editable-cp310-cp310-linux_x86_64.whl size=10573 sha256=ae3d90872dc4c128f83463251ce7d1e14546b9645f5d4c48aef7181fd9d2d062\n  Stored in directory: /tmp/pip-ephem-wheel-cache-trew8ahp/wheels/74/c0/02/1809a4936a6029d67f70271cfde7a3146771b175dff0246a2d\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=b4f0840ab7f799ef26b9f03322d781ea923a62b227207f6c026da367438bec51\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n  Building wheel for iopath (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=65efb03924558b1f42d6c5d0392f94faf3bbfcb40b016462895acdd953655a3a\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built SAM-2 antlr4-python3-runtime iopath\nInstalling collected packages: antlr4-python3-runtime, portalocker, omegaconf, connected-components-3d, iopath, hydra-core, monai, SAM-2\nSuccessfully installed SAM-2-1.0 antlr4-python3-runtime-4.9.3 connected-components-3d-3.19.0 hydra-core-1.3.2 iopath-0.1.10 monai-1.4.0 omegaconf-2.3.0 portalocker-2.10.1\n--2024-11-01 18:55:09--  https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.158.20.111, 108.158.20.120, 108.158.20.43, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.158.20.111|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 155906050 (149M) [application/vnd.snesdev-page-table]\nSaving to: './checkpoints/sam2_hiera_tiny.pt'\n\nsam2_hiera_tiny.pt  100%[===================>] 148.68M   293MB/s    in 0.5s    \n\n2024-11-01 18:55:09 (293 MB/s) - './checkpoints/sam2_hiera_tiny.pt' saved [155906050/155906050]\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwget https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt -P ./checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopytree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/ddr-segmentation-dataset/kaggle/working/data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/data/train/gts/007-2402-100.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m os\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/data/train/images/007-2402-100.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:559\u001b[0m, in \u001b[0;36mcopytree\u001b[0;34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m os\u001b[38;5;241m.\u001b[39mscandir(src) \u001b[38;5;28;01mas\u001b[39;00m itr:\n\u001b[1;32m    558\u001b[0m     entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itr)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_copytree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_dangling_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/shutil.py:457\u001b[0m, in \u001b[0;36m_copytree\u001b[0;34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     ignored_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 457\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirs_exist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    459\u001b[0m use_srcentry \u001b[38;5;241m=\u001b[39m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy2 \u001b[38;5;129;01mor\u001b[39;00m copy_function \u001b[38;5;129;01mis\u001b[39;00m copy\n","File \u001b[0;32m/opt/conda/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/kaggle/working/data'"],"ename":"FileExistsError","evalue":"[Errno 17] File exists: '/kaggle/working/data'","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport os\njoin = os.path.join\nlistdir = os.listdir\nmakedirs = os.makedirs\nfrom tqdm import tqdm\nimport multiprocessing as mp\nimport cv2\nimport argparse","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:56:23.218064Z","iopub.execute_input":"2024-11-01T18:56:23.219005Z","iopub.status.idle":"2024-11-01T18:56:23.224635Z","shell.execute_reply.started":"2024-11-01T18:56:23.218951Z","shell.execute_reply":"2024-11-01T18:56:23.223599Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"gts_path = '/kaggle/working/data/valid/gts'\nimg_path = '/kaggle/input/ddr-segmentation-dataset/kaggle/working/data/train/images'\nfor f in os.listdir(gts_path):\n    gts_file = np.load(os.path.join(gts_path,f))\n    if len(np.unique(gts_file)) <= 1:\n        print(f)\n        print(np.unique(gts_file))\n        \n    # print(np.unique(gts_file))\n# print(np.load(os.path.join(img_path,os.listdir(img_path)[0])).shape)\n\n#valid\n#007-2983-100.npy\n\n#train\n# 007-2402-100.npy\n# 007-2366-100.npy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:56:23.693412Z","iopub.execute_input":"2024-11-01T18:56:23.693823Z","iopub.status.idle":"2024-11-01T18:56:23.848312Z","shell.execute_reply.started":"2024-11-01T18:56:23.693784Z","shell.execute_reply":"2024-11-01T18:56:23.847508Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import hydra\nhydra.core.global_hydra.GlobalHydra.instance().clear()\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\njoin = os.path.join\nfrom tqdm import tqdm\nfrom skimage import transform\nimport torch\nimport torchvision\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport monai\nimport torch.nn.functional as F\nimport argparse\nimport random\nfrom datetime import datetime\nimport shutil\nimport glob\nfrom sam2.build_sam import build_sam2\nfrom typing import List, Optional, Tuple\nfrom sam2.modeling.sam2_base import SAM2Base\nfrom sam2.utils.transforms import SAM2Transforms\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:56:28.088443Z","iopub.execute_input":"2024-11-01T18:56:28.089065Z","iopub.status.idle":"2024-11-01T18:57:21.588895Z","shell.execute_reply.started":"2024-11-01T18:56:28.089024Z","shell.execute_reply":"2024-11-01T18:57:21.587740Z"}},"outputs":[{"name":"stderr","text":"/kaggle/working/MedSAM/sam2/modeling/sam/transformer.py:22: UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n  OLD_GPU, USE_FLASH_ATTN, MATH_KERNEL_ON = get_sdpa_settings()\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(2024)\n\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"  # export OMP_NUM_THREADS=4\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"  # export OPENBLAS_NUM_THREADS=4\nos.environ[\"MKL_NUM_THREADS\"] = \"6\"  # export MKL_NUM_THREADS=6\nos.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"4\"  # export VECLIB_MAXIMUM_THREADS=4\nos.environ[\"NUMEXPR_NUM_THREADS\"] = \"6\"  # export NUMEXPR_NUM_THREADS=6\n\ndef show_mask(mask, ax, random_color=False):\n    if random_color:\n        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n    else:\n        color = np.array([251 / 255, 252 / 255, 30 / 255, 0.6])\n    h, w = mask.shape[-2:]\n    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n    ax.imshow(mask_image)\n\n\ndef show_box(box, ax):\n    x0, y0 = box[0], box[1]\n    w, h = box[2] - box[0], box[3] - box[1]\n    ax.add_patch(\n        plt.Rectangle((x0, y0), w, h, edgecolor=\"blue\", facecolor=(0, 0, 0, 0), lw=2)\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:57:26.787621Z","iopub.execute_input":"2024-11-01T18:57:26.788450Z","iopub.status.idle":"2024-11-01T18:57:26.806690Z","shell.execute_reply.started":"2024-11-01T18:57:26.788408Z","shell.execute_reply":"2024-11-01T18:57:26.805880Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class NpyDataset(Dataset):\n    def __init__(self, data_root, bbox_shift=20):\n        \n        self.data_root = data_root\n        self.gt_path = join(data_root, \"gts\")\n        self.img_path = join(data_root, \"images\")\n        self.gt_path_files = sorted(\n            glob.glob(join(self.gt_path, \"*.npy\"), recursive=True)\n        )\n        # print(self.gt_path_files)\n        # self.gt_path_files = self.gt_path_files\n        # self.gt_path_files = [\n        #     file\n        #     for file in self.gt_path_files\n        #     if os.path.isfile(join(self.img_path, os.path.basename(file)))\n        # ]\n        self.bbox_shift = bbox_shift\n        self._transform = SAM2Transforms(resolution=1024, mask_threshold=0)\n        print(f\"number of images: {len(self.gt_path_files)}\")\n        # print(self.data_root)\n        # print(self.gt_path)\n        # print(self.gt_path_files)\n\n\n\n    def __len__(self):\n        return len(self.gt_path_files)\n\n    def __getitem__(self, index):\n        # load npy image (1024, 1024, 3), [0,1]\n        img_name = os.path.basename(self.gt_path_files[index])\n        img = np.load(\n            join(self.img_path, img_name), \"r\", allow_pickle=True\n        )  # (1024, 1024, 3)\n        # convert the shape to (3, H, W)\n        img_1024 = self._transform(img.copy())\n        gt = np.load(\n            self.gt_path_files[index], \"r\", allow_pickle=True\n        )  # multiple labels [0, 1,4,5...], (256,256)\n        assert img_name == os.path.basename(self.gt_path_files[index]), (\n            \"img gt name error\" + self.gt_path_files[index] + self.npy_files[index]\n        )\n        assert gt.shape == (256, 256), \"ground truth should be 256x256\"\n        label_ids = np.unique(gt)[1:]\n        # print(label_ids)\n        # print(img_name)\n        gt2D = np.uint8(\n            gt == random.choice(label_ids.tolist())\n        )  # only one label, (256, 256)\n        assert np.max(gt2D) == 1 and np.min(gt2D) == 0.0, \"ground truth should be 0, 1\"\n        y_indices, x_indices = np.where(gt2D > 0)\n        x_min, x_max = np.min(x_indices), np.max(x_indices)\n        y_min, y_max = np.min(y_indices), np.max(y_indices)\n        # add perturbation to bounding box coordinates\n        H, W = gt2D.shape\n        x_min = max(0, x_min - random.randint(0, self.bbox_shift))\n        x_max = min(W, x_max + random.randint(0, self.bbox_shift))\n        y_min = max(0, y_min - random.randint(0, self.bbox_shift))\n        y_max = min(H, y_max + random.randint(0, self.bbox_shift))\n\n        bboxes = np.array([x_min, y_min, x_max, y_max])*4 ## scale bbox from 256 to 1024\n\n        return (\n            img_1024, ## [3, 1024, 1024]\n            torch.tensor(gt2D[None, :, :]).long(), ## [1, 256, 256]\n            torch.tensor(bboxes).float(), \n            img_name,\n        )\n\n\n\n# # sanity test of dataset class\ntr_dataset = NpyDataset('/kaggle/working/data/train')\ntr_dataloader = DataLoader(tr_dataset, batch_size=4, shuffle=True)\nimages, gts, bboxes, names_temp = next(iter(tr_dataloader))\nidx = random.randint(0, images.shape[0]-1)\ninv_sam2_transform = torchvision.transforms.Compose(\n    [\n        torchvision.transforms.Normalize(mean=[0, 0, 0], std=[1 / i for i in tr_dataset._transform.std]),\n        torchvision.transforms.Normalize(mean=[-1 * i for i in tr_dataset._transform.mean], std=[1, 1, 1]),\n    ]\n)\n_, axs = plt.subplots(1, 2, figsize=(25, 25))\naxs[0].imshow(\n    inv_sam2_transform(images[idx].clone()).permute(1, 2, 0).numpy()\n)\nshow_mask(\n    cv2.resize(\n        gts[idx].squeeze(0).numpy(),\n        (1024, 1024),\n        interpolation=cv2.INTER_NEAREST\n    ),\n    axs[0]\n)\nshow_box(bboxes[idx].numpy(), axs[0])\naxs[0].axis(\"off\")\naxs[0].set_title(names_temp[idx])\nidx = random.randint(0, images.shape[0]-1)\naxs[1].imshow(\n    inv_sam2_transform(images[idx].clone()).permute(1, 2, 0).numpy()\n)\nshow_mask(\n    cv2.resize(\n        gts[idx].clone().squeeze(0).numpy(),\n        (1024, 1024),\n        interpolation=cv2.INTER_NEAREST\n    ),\n    axs[1]\n)\nshow_box(bboxes[idx].numpy(), axs[1])\naxs[1].axis(\"off\")\naxs[1].set_title(names_temp[idx])\nplt.subplots_adjust(wspace=0.01, hspace=0)\nplt.savefig(\"./data_sanitycheck.png\", bbox_inches=\"tight\", dpi=300)\nplt.close()\n\nrun_id = datetime.now().strftime(\"%Y%m%d-%H%M\")\nmodel_save_path = join('/kaggle/working/MedSAM/work_dir', 'DDR_segmentation' + \"-\" + run_id)\ndevice = torch.device('cuda:0')\n\nclass MedSAM2(nn.Module):\n    def __init__(\n        self,\n        model,\n    ):\n        super().__init__()\n        self.sam2_model = model\n        # freeze prompt encoder\n        for param in self.sam2_model.sam_prompt_encoder.parameters():\n            param.requires_grad = False\n        \n\n    def forward(self, image, box):\n        \"\"\"\n        image: (B, 3, 1024, 1024)\n        box: (B, 2, 2)\n        \"\"\"\n        _features = self._image_encoder(image)\n        img_embed, high_res_features = _features[\"image_embed\"], _features[\"high_res_feats\"]\n        # do not compute gradients for prompt encoder\n        with torch.no_grad():\n            box_torch = torch.as_tensor(box, dtype=torch.float32, device=image.device)\n            if len(box_torch.shape) == 2:\n                box_coords = box_torch.reshape(-1, 2, 2) # (B, 4) to (B, 2, 2)\n                box_labels = torch.tensor([[2, 3]], dtype=torch.int, device=image.device)\n                box_labels = box_labels.repeat(box_torch.size(0), 1)\n            concat_points = (box_coords, box_labels)\n\n            sparse_embeddings, dense_embeddings = self.sam2_model.sam_prompt_encoder(\n                points=concat_points,\n                boxes=None,\n                masks=None,\n            )\n        low_res_masks_logits, iou_predictions, sam_tokens_out, object_score_logits = self.sam2_model.sam_mask_decoder(\n            image_embeddings=img_embed, # (B, 256, 64, 64)\n            image_pe=self.sam2_model.sam_prompt_encoder.get_dense_pe(),\n            sparse_prompt_embeddings=sparse_embeddings,\n            dense_prompt_embeddings=dense_embeddings,\n            multimask_output=False,\n            repeat_image=False,\n            high_res_features=high_res_features,\n        )\n\n        return low_res_masks_logits\n    \n    def _image_encoder(self, input_image):\n        backbone_out = self.sam2_model.forward_image(input_image)\n        _, vision_feats, _, _ = self.sam2_model._prepare_backbone_features(backbone_out)\n        # Add no_mem_embed, which is added to the lowest rest feat. map during training on videos\n        if self.sam2_model.directly_add_no_mem_embed:\n            vision_feats[-1] = vision_feats[-1] + self.sam2_model.no_mem_embed\n        bb_feat_sizes = [(256, 256), (128, 128), (64, 64)]\n        feats = [\n            feat.permute(1, 2, 0).view(input_image.size(0), -1, *feat_size)\n            for feat, feat_size in zip(vision_feats[::-1], bb_feat_sizes[::-1])\n        ][::-1]\n        _features = {\"image_embed\": feats[-1], \"high_res_feats\": feats[:-1]}\n\n        return _features\n\n\n# %%","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:57:31.069297Z","iopub.execute_input":"2024-11-01T18:57:31.069699Z","iopub.status.idle":"2024-11-01T18:57:45.590160Z","shell.execute_reply.started":"2024-11-01T18:57:31.069660Z","shell.execute_reply":"2024-11-01T18:57:45.589129Z"}},"outputs":[{"name":"stdout","text":"number of images: 606\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def main():\n    torch.cuda.empty_cache()\n    os.makedirs(model_save_path, exist_ok=True)\n    # shutil.copyfile(\n    #     ,join(model_save_path, run_id + \"_\" + os.path.basename(__file__))\n    # )\n\n    model_cfg = 'sam2_hiera_t.yaml'\n    sam2_checkpoint = '/kaggle/working/MedSAM/checkpoints/sam2_hiera_tiny.pt'\n    sam2_model = build_sam2(model_cfg, sam2_checkpoint, device= device, apply_postprocessing=True)\n    medsam_model = MedSAM2(model=sam2_model)\n    medsam_model.train()\n\n    print(\n        \"Number of total parameters: \",\n        sum(p.numel() for p in medsam_model.parameters()),\n    ) \n    print(\n        \"Number of trainable parameters: \",\n        sum(p.numel() for p in medsam_model.parameters() if p.requires_grad),\n    )  \n\n    img_mask_encdec_params = list(medsam_model.sam2_model.image_encoder.parameters()) + list(\n        medsam_model.sam2_model.sam_mask_decoder.parameters()\n    )\n    optimizer = torch.optim.AdamW(\n        img_mask_encdec_params, lr=6e-5, weight_decay=0.01\n    )\n    print(\n        \"Number of image encoder and mask decoder parameters: \",\n        sum(p.numel() for p in img_mask_encdec_params if p.requires_grad),\n    )  \n    seg_loss = monai.losses.DiceLoss(sigmoid=True, squared_pred=True, reduction=\"mean\")\n    # cross entropy loss\n    ce_loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n\n    num_epochs = 50\n    losses = []\n    best_loss = 1e10\n    train_dataset = NpyDataset('/kaggle/working/data/train')\n\n    print(\"Number of training samples: \", len(train_dataset))\n    train_dataloader = DataLoader(\n        train_dataset,\n        batch_size=4,\n        shuffle=False,\n        num_workers=0,\n        pin_memory=True,\n    )\n\n    start_epoch = 0\n    resume = None\n    if resume is not None:\n        if os.path.isfile(resume):\n            ## Map model to be loaded to specified single GPU\n            print(\"=> loading checkpoint '{}'\".format(resume))\n            checkpoint = torch.load(resume, map_location=device)\n            start_epoch = checkpoint[\"epoch\"] + 1\n            medsam_model.load_state_dict(checkpoint[\"model\"], strict=True)\n            optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n    for epoch in range(start_epoch, num_epochs):\n        epoch_loss = 0\n        for step, (image, gt2D, boxes, _) in enumerate(tqdm(train_dataloader)):\n            optimizer.zero_grad()\n            boxes_np = boxes.detach().cpu().numpy()\n            image, gt2D = image.to(device), gt2D.to(device)\n            \n            medsam_pred = medsam_model(image, boxes_np)\n            loss = seg_loss(medsam_pred, gt2D) + ce_loss(medsam_pred, gt2D.float())                \n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            epoch_loss += loss.item()\n\n        epoch_loss /= step\n        losses.append(epoch_loss)\n        print(\n            f'Time: {datetime.now().strftime(\"%Y%m%d-%H%M\")}, Epoch: {epoch}, Loss: {epoch_loss}'\n        )\n        ## save the latest model\n        checkpoint = {\n            \"model\": medsam_model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n            \"epoch\": epoch,\n        }\n        torch.save(checkpoint, join(model_save_path, \"medsam_model_latest.pth\"))\n        ## save the best model\n        if epoch_loss < best_loss:\n            best_loss = epoch_loss\n            checkpoint = {\n                \"model\": medsam_model.state_dict(),\n                \"optimizer\": optimizer.state_dict(),\n                \"epoch\": epoch,\n            }\n            torch.save(checkpoint, join(model_save_path, \"medsam_model_best.pth\"))\n\n        # %% plot loss\n        plt.plot(losses)\n        plt.title(\"Dice + Cross Entropy Loss\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"Loss\")\n        plt.savefig(join(model_save_path, 'DDR_segmentation' + \"train_loss.png\"))\n        plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:57:45.591756Z","iopub.execute_input":"2024-11-01T18:57:45.592080Z","iopub.status.idle":"2024-11-01T18:57:45.611220Z","shell.execute_reply.started":"2024-11-01T18:57:45.592048Z","shell.execute_reply":"2024-11-01T18:57:45.610210Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T18:57:52.846679Z","iopub.execute_input":"2024-11-01T18:57:52.847221Z","iopub.status.idle":"2024-11-01T21:58:37.596851Z","shell.execute_reply.started":"2024-11-01T18:57:52.847180Z","shell.execute_reply":"2024-11-01T21:58:37.596056Z"}},"outputs":[{"name":"stdout","text":"Number of total parameters:  38945986\nNumber of trainable parameters:  38939766\nNumber of image encoder and mask decoder parameters:  31434245\nnumber of images: 606\nNumber of training samples:  606\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:48<00:00,  1.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1901, Epoch: 0, Loss: 0.8202985047504602\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:40<00:00,  1.45s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1905, Epoch: 1, Loss: 0.7179508499357085\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1909, Epoch: 2, Loss: 0.6504167734787164\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1912, Epoch: 3, Loss: 0.672481418248044\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1916, Epoch: 4, Loss: 0.6049868137828561\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:37<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1920, Epoch: 5, Loss: 0.5685532175941973\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:37<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1923, Epoch: 6, Loss: 0.5613255365597491\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1927, Epoch: 7, Loss: 0.5250182005249902\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:37<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1931, Epoch: 8, Loss: 0.5119144787752865\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:39<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1934, Epoch: 9, Loss: 0.5625719934307187\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1938, Epoch: 10, Loss: 0.502448598724722\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1942, Epoch: 11, Loss: 0.4872152829259042\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1945, Epoch: 12, Loss: 0.5099927754887682\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1949, Epoch: 13, Loss: 0.45814404537938286\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1953, Epoch: 14, Loss: 0.47361058549375723\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:39<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-1956, Epoch: 15, Loss: 0.453109199736292\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2000, Epoch: 16, Loss: 0.43883880064976927\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:39<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2004, Epoch: 17, Loss: 0.4622193831481681\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:38<00:00,  1.44s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2007, Epoch: 18, Loss: 0.4530159468386347\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2011, Epoch: 19, Loss: 0.42483416712836714\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:29<00:00,  1.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2014, Epoch: 20, Loss: 0.4350249817138476\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:29<00:00,  1.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2018, Epoch: 21, Loss: 0.41596302905718224\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:29<00:00,  1.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2021, Epoch: 22, Loss: 0.38155528382453696\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:28<00:00,  1.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2025, Epoch: 23, Loss: 0.4078515059382513\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:29<00:00,  1.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2028, Epoch: 24, Loss: 0.42303732675284345\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:29<00:00,  1.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2032, Epoch: 25, Loss: 0.4303294986344578\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:29<00:00,  1.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2036, Epoch: 26, Loss: 0.3923964473042662\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:28<00:00,  1.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2039, Epoch: 27, Loss: 0.4013907601941217\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:28<00:00,  1.37s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2042, Epoch: 28, Loss: 0.3647854795667115\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:31<00:00,  1.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2046, Epoch: 29, Loss: 0.3866951532248679\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:32<00:00,  1.40s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2050, Epoch: 30, Loss: 0.37436757061093895\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:33<00:00,  1.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2053, Epoch: 31, Loss: 0.37277724788777084\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:31<00:00,  1.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2057, Epoch: 32, Loss: 0.3582719055972747\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:31<00:00,  1.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2100, Epoch: 33, Loss: 0.3727436478508772\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:30<00:00,  1.38s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2104, Epoch: 34, Loss: 0.38412831724923574\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:31<00:00,  1.39s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2107, Epoch: 35, Loss: 0.3941146820684932\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:33<00:00,  1.41s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2111, Epoch: 36, Loss: 0.3804833437314433\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2115, Epoch: 37, Loss: 0.3850921608988714\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:37<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2118, Epoch: 38, Loss: 0.3905337472625126\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:37<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2122, Epoch: 39, Loss: 0.3551316040518712\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:35<00:00,  1.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2125, Epoch: 40, Loss: 0.3288607785812832\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2129, Epoch: 41, Loss: 0.3357540268950728\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2133, Epoch: 42, Loss: 0.3561238179489082\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2136, Epoch: 43, Loss: 0.3666807677325429\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2140, Epoch: 44, Loss: 0.3552143419691861\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2144, Epoch: 45, Loss: 0.3482402947034366\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:35<00:00,  1.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2147, Epoch: 46, Loss: 0.35864290744380406\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:37<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2151, Epoch: 47, Loss: 0.35015468622190843\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.42s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2154, Epoch: 48, Loss: 0.3639808385933608\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 152/152 [03:36<00:00,  1.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"Time: 20241101-2158, Epoch: 49, Loss: 0.3406029386038812\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!zip -r ddr_output.zip /kaggle/working/MedSAM/work_dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-01T21:58:37.598952Z","iopub.execute_input":"2024-11-01T21:58:37.599255Z","iopub.status.idle":"2024-11-01T21:59:18.463342Z","shell.execute_reply.started":"2024-11-01T21:58:37.599222Z","shell.execute_reply":"2024-11-01T21:59:18.462337Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"  adding: kaggle/working/MedSAM/work_dir/ (stored 0%)\n  adding: kaggle/working/MedSAM/work_dir/DDR_segmentation-20241101-1857/ (stored 0%)\n  adding: kaggle/working/MedSAM/work_dir/DDR_segmentation-20241101-1857/medsam_model_best.pth (deflated 8%)\n  adding: kaggle/working/MedSAM/work_dir/DDR_segmentation-20241101-1857/medsam_model_latest.pth (deflated 8%)\n  adding: kaggle/working/MedSAM/work_dir/DDR_segmentation-20241101-1857/DDR_segmentationtrain_loss.png (deflated 9%)\n  adding: kaggle/working/MedSAM/work_dir/README.md (stored 0%)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}